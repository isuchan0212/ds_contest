{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lasso_Daeryun.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zIJ05nx6Qa8","executionInfo":{"status":"ok","timestamp":1639566061484,"user_tz":-540,"elapsed":23210,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"5dd8f71a-be34-47e9-cbe2-38e44036e52d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","from sklearn.metrics import make_scorer"],"metadata":{"id":"wnaKGBoY6q1k","executionInfo":{"status":"ok","timestamp":1639567861479,"user_tz":-540,"elapsed":305,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/gdrive/My Drive/DS_contest/Beforelasso.csv')\n","df.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"QY2abjPh6x5G","executionInfo":{"status":"ok","timestamp":1639567586959,"user_tz":-540,"elapsed":319,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"acab7db7-11c1-4465-d863-f66dc86cc4ac"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>No</th>\n","      <th>MD (All Wells) (ft)</th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole direction (N/S)/(E/W)</th>\n","      <th>Bot-Hole Easting (NAD83)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Total Fluid Pumped (m3)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Completed Length (m)</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Load Fluid Rec (m3)</th>\n","      <th>Load Fluid (m3)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Avg Proppant Placed / Meter (tonne)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Avg Proppant 1 Placed (tonne)</th>\n","      <th>Total Proppant 1 Placed (tonne)</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>Total Sand Proppant Placed (tonne)</th>\n","      <th>Y_first6</th>\n","      <th>SF_oil</th>\n","      <th>SF_water</th>\n","      <th>SF_slickwater</th>\n","      <th>PC_ceramic</th>\n","      <th>PC_sand</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>354</td>\n","      <td>15384</td>\n","      <td>10746</td>\n","      <td>0.583087</td>\n","      <td>0.520701</td>\n","      <td>0.202393</td>\n","      <td>1197.61</td>\n","      <td>66.53</td>\n","      <td>3214.70</td>\n","      <td>178.59</td>\n","      <td>18</td>\n","      <td>1249.60</td>\n","      <td>73.50</td>\n","      <td>1148.37</td>\n","      <td>3248.30</td>\n","      <td>2.57</td>\n","      <td>0.96</td>\n","      <td>40.0</td>\n","      <td>35.48</td>\n","      <td>638.70</td>\n","      <td>638.70</td>\n","      <td>558.91</td>\n","      <td>99580.58333</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>372</td>\n","      <td>20167</td>\n","      <td>10440</td>\n","      <td>1.059932</td>\n","      <td>0.402927</td>\n","      <td>0.242269</td>\n","      <td>4212.32</td>\n","      <td>117.01</td>\n","      <td>9727.20</td>\n","      <td>270.20</td>\n","      <td>36</td>\n","      <td>2711.90</td>\n","      <td>77.41</td>\n","      <td>1604.27</td>\n","      <td>11438.43</td>\n","      <td>3.59</td>\n","      <td>1.55</td>\n","      <td>60.0</td>\n","      <td>13.80</td>\n","      <td>496.97</td>\n","      <td>496.97</td>\n","      <td>3715.35</td>\n","      <td>82942.66667</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>383</td>\n","      <td>18832</td>\n","      <td>10745</td>\n","      <td>1.913723</td>\n","      <td>0.351151</td>\n","      <td>0.274381</td>\n","      <td>5131.40</td>\n","      <td>95.03</td>\n","      <td>52997.80</td>\n","      <td>981.44</td>\n","      <td>54</td>\n","      <td>2275.37</td>\n","      <td>42.88</td>\n","      <td>914.98</td>\n","      <td>52997.80</td>\n","      <td>23.29</td>\n","      <td>2.26</td>\n","      <td>55.0</td>\n","      <td>95.03</td>\n","      <td>5131.40</td>\n","      <td>0.00</td>\n","      <td>5131.40</td>\n","      <td>55833.66667</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>395</td>\n","      <td>20243</td>\n","      <td>10884</td>\n","      <td>0.185481</td>\n","      <td>0.231014</td>\n","      <td>0.305237</td>\n","      <td>3044.00</td>\n","      <td>49.90</td>\n","      <td>42791.76</td>\n","      <td>701.50</td>\n","      <td>61</td>\n","      <td>2687.20</td>\n","      <td>43.04</td>\n","      <td>0.00</td>\n","      <td>51059.60</td>\n","      <td>15.92</td>\n","      <td>1.13</td>\n","      <td>55.0</td>\n","      <td>49.90</td>\n","      <td>3044.00</td>\n","      <td>0.00</td>\n","      <td>3044.00</td>\n","      <td>95592.08333</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>397</td>\n","      <td>19085</td>\n","      <td>10916</td>\n","      <td>0.432910</td>\n","      <td>0.214301</td>\n","      <td>0.306795</td>\n","      <td>5374.00</td>\n","      <td>99.52</td>\n","      <td>50769.92</td>\n","      <td>940.18</td>\n","      <td>54</td>\n","      <td>2351.45</td>\n","      <td>42.70</td>\n","      <td>0.00</td>\n","      <td>53236.05</td>\n","      <td>21.59</td>\n","      <td>2.29</td>\n","      <td>55.0</td>\n","      <td>99.09</td>\n","      <td>5351.00</td>\n","      <td>0.00</td>\n","      <td>5374.00</td>\n","      <td>104730.33330</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0   No  MD (All Wells) (ft)  ...  SF_slickwater  PC_ceramic  PC_sand\n","0           0  354                15384  ...              0           1        0\n","1           1  372                20167  ...              0           1        0\n","2           2  383                18832  ...              0           0        1\n","3           3  395                20243  ...              0           0        1\n","4           4  397                19085  ...              0           0        1\n","\n","[5 rows x 29 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df = df.drop('Unnamed: 0', axis=1)"],"metadata":{"id":"8qvTrzS47qPu","executionInfo":{"status":"ok","timestamp":1639567588078,"user_tz":-540,"elapsed":3,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hK9mgtZx-PIC","executionInfo":{"status":"ok","timestamp":1639567588409,"user_tz":-540,"elapsed":3,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"5367df47-e44f-4e7d-a020-69abebe9febe"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['No', 'MD (All Wells) (ft)', 'TVD (ft)',\n","       'Bot-Hole direction (N/S)/(E/W)', 'Bot-Hole Easting (NAD83)',\n","       'Bot-Hole Northing (NAD83)', 'Total Proppant Placed (tonne)',\n","       'Avg Proppant Placed per Stage (tonne)', 'Total Fluid Pumped (m3)',\n","       'Avg Fluid Pumped per Stage (m3)', 'Stages Actual',\n","       'Completed Length (m)', 'Avg Frac Spacing (m)', 'Load Fluid Rec (m3)',\n","       'Load Fluid (m3)', 'Avg Fluid Pumped / Meter (m3)',\n","       'Avg Proppant Placed / Meter (tonne)', 'Proppant Size 1',\n","       'Avg Proppant 1 Placed (tonne)', 'Total Proppant 1 Placed (tonne)',\n","       'Total Ceramic Proppant Placed (tonne)',\n","       'Total Sand Proppant Placed (tonne)', 'Y_first6', 'SF_oil', 'SF_water',\n","       'SF_slickwater', 'PC_ceramic', 'PC_sand'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df_std = df.drop(['No','SF_oil','SF_water','SF_slickwater','PC_ceramic','PC_sand','Y_first6'],axis=1)\n","df_normal = df.drop(['No','SF_oil','SF_water','SF_slickwater','PC_ceramic','PC_sand','Y_first6'],axis=1)"],"metadata":{"id":"KjVpemDKZEPI","executionInfo":{"status":"ok","timestamp":1639567594217,"user_tz":-540,"elapsed":411,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def feature_scaling(df, scaling_strategy=\"z-score\", column=None):\n","    if column == None:\n","        column = [column_name for column_name in df.columns]\n","    for column_name in column:\n","        if scaling_strategy == \"min-max\":\n","            df[column_name] = ( df[column_name] - df[column_name].min() ) /\\\n","                            (df[column_name].max() - df[column_name].min()) \n","        elif scaling_strategy == \"z-score\":\n","            df[column_name] = ( df[column_name] - \\\n","                               df[column_name].mean() ) /\\\n","                            (df[column_name].std() )\n","    return df"],"metadata":{"id":"OdfXVt5xbDF3","executionInfo":{"status":"ok","timestamp":1639567598822,"user_tz":-540,"elapsed":306,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_std = feature_scaling(df_std)\n","df_normal = feature_scaling(df_normal, scaling_strategy = 'min-max')\n","df_std.head(5), df_normal.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEuXTkajcmt6","executionInfo":{"status":"ok","timestamp":1639567600670,"user_tz":-540,"elapsed":351,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"beaf7bb9-73c0-45b4-8260-aa141bc927b6"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(   MD (All Wells) (ft)  ...  Total Sand Proppant Placed (tonne)\n"," 0            -1.562520  ...                           -2.107496\n"," 1             0.933927  ...                           -0.464036\n"," 2             0.237135  ...                            0.273257\n"," 3             0.973595  ...                           -0.813587\n"," 4             0.369186  ...                            0.399571\n"," \n"," [5 rows x 21 columns],\n","    MD (All Wells) (ft)  ...  Total Sand Proppant Placed (tonne)\n"," 0             0.152973  ...                            0.016260\n"," 1             0.749283  ...                            0.345439\n"," 2             0.582845  ...                            0.493116\n"," 3             0.758758  ...                            0.275425\n"," 4             0.614387  ...                            0.518416\n"," \n"," [5 rows x 21 columns])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df_std['No'] = df['No']\n","df_std['SF_oil'] = df['SF_oil']\n","df_std['SF_water'] = df['SF_water']\n","df_std['SF_slickwater'] = df['SF_slickwater']\n","df_std['PC_ceramic'] = df['PC_ceramic']\n","df_std['PC_sand'] = df['PC_sand']\n","df_std['Y_first6'] = df['Y_first6']\n","df_normal['No'] = df['No']\n","df_normal['SF_oil'] = df['SF_oil']\n","df_normal['SF_water'] = df['SF_water']\n","df_normal['SF_slickwater'] = df['SF_slickwater']\n","df_normal['PC_ceramic'] = df['PC_ceramic']\n","df_normal['PC_sand'] = df['PC_sand']\n","df_normal['Y_first6'] = df['Y_first6']"],"metadata":{"id":"7c6WDsDZdWhU","executionInfo":{"status":"ok","timestamp":1639567605701,"user_tz":-540,"elapsed":325,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Lasso (Feature selection)"],"metadata":{"id":"UjCBS5j0VxSf"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","from sklearn.model_selection import train_test_split\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","x_normal = df_normal.drop(['No','Y_first6'],axis=1)\n","y = df['Y_first6']\n","lasso_reg = Lasso(alpha=350, normalize=False)"],"metadata":{"id":"Nfa0ovUcra1C","executionInfo":{"status":"ok","timestamp":1639472097599,"user_tz":-540,"elapsed":776,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import make_scorer\n","\n","def sMAPE(actual_values, predicted_values, expsMAPE = False):\n","  '''\n","  logY를 regression하는 경우에 expsMAPE = True로 입력, 아니면 expsMAPE = False로 놔두면 됨\n","  reg_sMAPE = GridSearchCV(RandomForestRegressor(), {}, scoring=make_scorer(sMAPE, greater_is_better=False)) 이런식으로 쓰면됨\n","  reg_sMAPE.fit(x,y)\n","  '''\n","  if expsMAPE == True:\n","    predicted_values = np.exp(predicted_values)\n","    actual_values = np.exp(actual_values)\n","  return 1/len(actual_values) * np.sum(2*np.abs(actual_values - predicted_values) / (np.abs(actual_values) + np.abs(predicted_values)) * 100)"],"metadata":{"id":"LP-jLRm7Gbi6","executionInfo":{"status":"ok","timestamp":1639569819687,"user_tz":-540,"elapsed":219,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["reg_sMAPE = GridSearchCV(Lasso(), {}, scoring=make_scorer(sMAPE, greater_is_better=False),cv=5)\n","reg_sMAPE.fit(x_std,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEHqB-3BFRkD","executionInfo":{"status":"ok","timestamp":1639472106331,"user_tz":-540,"elapsed":374,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"ee8cd74d-f144-4c69-9727-b73f83b8c227"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+11, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.872e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+11, tolerance: 6.829e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=Lasso(normalize=False), param_grid={},\n","             scoring=make_scorer(sMAPE, greater_is_better=False))"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#feature selection\n","x_std_train, x_std_test, y_std_train, y_std_test = train_test_split(x_std, y, test_size = 0.2, random_state = 34)\n","std_pred = lasso_reg.fit(x_std_train, y_std_train)\n","y_std_pred = lasso_reg.predict(x_std_test)\n","lasso_reg.coef_, lasso_reg.intercept_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEe2aCX-IjU9","executionInfo":{"status":"ok","timestamp":1639472585204,"user_tz":-540,"elapsed":406,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"1c08181a-a39f-4e1a-b851-53a40c24264b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([-0.00000000e+00,  1.06622383e+04,  2.52267935e+02,  0.00000000e+00,\n","        -1.33157818e+04,  3.26917224e+04, -1.24787137e+04,  0.00000000e+00,\n","        -0.00000000e+00,  0.00000000e+00, -4.97254400e+03,  1.15523001e+04,\n","        -0.00000000e+00, -3.79430397e+03, -3.51589317e+03, -0.00000000e+00,\n","        -2.84155491e+03, -0.00000000e+00,  6.42825469e+03,  8.83790261e+03,\n","         0.00000000e+00, -3.33741442e+04, -0.00000000e+00,  3.95837311e+03,\n","        -7.84264340e+02,  1.14039499e-12]), 81071.54032497448)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["index_list = np.arange(len(y_std_pred))\n","plt.plot(index_list, y_std_pred, '--', c='r', label = 'predict')\n","plt.plot(index_list, y_std_test, '-', c='g', label = 'real')\n","plt.title('y_pred and y_test')\n","plt.legend()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"Ku5axrN3Pvqz","executionInfo":{"status":"ok","timestamp":1639384623876,"user_tz":-540,"elapsed":907,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"4ec2a1c9-513c-4ea5-eae1-5cce1d872c9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f43cebcd950>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(index_list, y_std_test - y_std_pred, '-', c='g', label = 'std_residual')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"BLVgQtvGP8eS","executionInfo":{"status":"ok","timestamp":1639384533390,"user_tz":-540,"elapsed":311,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"b08a2b2e-9b38-48a1-ca45-1047698b2e38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f43cf13ba10>]"]},"metadata":{},"execution_count":20},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["'''\n","def sMAPE(a, f):\n","  return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)\n","def mse_over_billion(a, f):\n","  return np.mean((a-f)**2) / 1000000000\n","'''"],"metadata":{"id":"Rxj-sN78QCgc","executionInfo":{"status":"ok","timestamp":1639567885267,"user_tz":-540,"elapsed":234,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(sMAPE(y_std_pred,y_std_test))\n","print(mse_over_billion(y_std_pred,y_std_test))"],"metadata":{"id":"v0NSE83J3GYa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Min-Max normalization은 확실히 별로임. Standardization으로 해야할듯."],"metadata":{"id":"nlcopzaSYEur"}},{"cell_type":"code","source":["''' 선택한 features: \n","'TVD (ft)', 'Bot-Hole Northing (NAD83)', 'Total Proppant Placed (tonne)', 'Avg Proppant Placed per Stage (tonne)', \n","'Avg Fluid Pumped per Stage (m3)', 'Stages Actual', 'Avg Frac Spacing (m)', 'Avg Fluid Pumped / Meter (m3)',\n","'Proppant Size 1', 'Total Ceramic Proppant Placed (tonne)', 'SF_oil', 'SF_slickwater' '''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"ukvxcyGsXAv1","executionInfo":{"status":"ok","timestamp":1639233673685,"user_tz":-540,"elapsed":14,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"05a4169b-e389-4b7e-fa05-230944cd819f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\" 선택한 features: \\n'TVD (ft)', 'Bot-Hole Northing (NAD83)', 'Total Proppant Placed (tonne)', 'Avg Proppant Placed per Stage (tonne)', \\n'Avg Fluid Pumped per Stage (m3)', 'Stages Actual', 'Avg Frac Spacing (m)', 'Avg Fluid Pumped / Meter (m3)',\\n'Proppant Size 1', 'Total Ceramic Proppant Placed (tonne)', 'SF_oil', 'SF_slickwater' \""]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["Lasso"],"metadata":{"id":"21TPHLrtR0gw"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = df['Y_first6']"],"metadata":{"id":"43p2dd0KRvIJ","executionInfo":{"status":"ok","timestamp":1639574919574,"user_tz":-540,"elapsed":265,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["alpha_list = {'alpha' : np.arange(2602,2608,0.1)}\n","reg_sMAPE = GridSearchCV(Lasso(), param_grid = alpha_list, scoring=make_scorer(sMAPE, greater_is_better=False),cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbxjrfwfR9-u","executionInfo":{"status":"ok","timestamp":1639575566874,"user_tz":-540,"elapsed":2805,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"c62b22c7-aaf8-45f6-adcd-a887c0a6f627"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 2604.9999999999973}\n"]}]},{"cell_type":"code","source":["lasso_opt = Lasso(alpha=2605).fit(x_std,y)\n","y_pred = lasso_opt.predict(x_std)\n","print(sMAPE(y, y_pred, False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVdbomoSTk7a","executionInfo":{"status":"ok","timestamp":1639575615584,"user_tz":-540,"elapsed":254,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"6eede9aa-434a-4fe7-ac6e-911780faa372"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["38.8852060130452\n"]}]},{"cell_type":"code","source":["std_pred = lasso_opt.fit(x_std, y)\n","y_pred = lasso_opt.predict(x_std)\n","lasso_opt.coef_, lasso_opt.intercept_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhQjXCPvUtpl","executionInfo":{"status":"ok","timestamp":1639575803614,"user_tz":-540,"elapsed":244,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"c4d481a7-4d07-41dd-f971-57661c285a14"},"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([     0.        ,   7656.03943888,      0.        ,     -0.        ,\n","        -14358.76166948,  17905.97814925,      0.        ,     -0.        ,\n","           -55.81911323,      0.        ,      0.        ,   2520.87328507,\n","             0.        ,     -0.        ,     -0.        ,      0.        ,\n","         -2037.66242272,      0.        ,      0.        ,      0.        ,\n","             0.        ,     -0.        ,      0.        ,      0.        ,\n","            -0.        ,      0.        ]), 79291.4431524893)"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["x_std.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZLQeeS3Vaha","executionInfo":{"status":"ok","timestamp":1639575832761,"user_tz":-540,"elapsed":239,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"dac4c519-4d37-4fbb-bb2f-61c98ecb3458"},"execution_count":120,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['MD (All Wells) (ft)', 'TVD (ft)', 'Bot-Hole direction (N/S)/(E/W)',\n","       'Bot-Hole Easting (NAD83)', 'Bot-Hole Northing (NAD83)',\n","       'Total Proppant Placed (tonne)',\n","       'Avg Proppant Placed per Stage (tonne)', 'Total Fluid Pumped (m3)',\n","       'Avg Fluid Pumped per Stage (m3)', 'Stages Actual',\n","       'Completed Length (m)', 'Avg Frac Spacing (m)', 'Load Fluid Rec (m3)',\n","       'Load Fluid (m3)', 'Avg Fluid Pumped / Meter (m3)',\n","       'Avg Proppant Placed / Meter (tonne)', 'Proppant Size 1',\n","       'Avg Proppant 1 Placed (tonne)', 'Total Proppant 1 Placed (tonne)',\n","       'Total Ceramic Proppant Placed (tonne)',\n","       'Total Sand Proppant Placed (tonne)', 'SF_oil', 'SF_water',\n","       'SF_slickwater', 'PC_ceramic', 'PC_sand'],\n","      dtype='object')"]},"metadata":{},"execution_count":120}]},{"cell_type":"markdown","source":["Log Lasso"],"metadata":{"id":"QPRq9_kfHH1F"}},{"cell_type":"code","source":["import math\n","log_list = []\n","for i in df_std['Y_first6']:\n","  log_list.append(math.log(i))\n","\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = log_list"],"metadata":{"id":"KdmrKwByHHfD","executionInfo":{"status":"ok","timestamp":1639575961472,"user_tz":-540,"elapsed":2,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["alpha_list = {'alpha' : np.arange(0.02,0.04,0.001)}\n","reg_sMAPE = GridSearchCV(Lasso(), param_grid = alpha_list, scoring=make_scorer(expsMAPE, greater_is_better=False), cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztgTH9c8H6-o","executionInfo":{"status":"ok","timestamp":1639576179568,"user_tz":-540,"elapsed":874,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"b4f0e84b-83eb-43fa-bd70-92abd519a5bf"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 0.03100000000000001}\n"]}]},{"cell_type":"code","source":["loglasso_opt = Lasso(alpha=0.031).fit(x_std,y)\n","y_pred = loglasso_opt.predict(x_std)\n","print(sMAPE(y, y_pred, True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYIpDNWaWeQr","executionInfo":{"status":"ok","timestamp":1639576189777,"user_tz":-540,"elapsed":234,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"fd1c311b-5e3c-4437-b749-5cc24ad53a2e"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["36.86207494742843\n"]}]},{"cell_type":"code","source":["loglasso_opt.coef_, loglasso_opt.intercept_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0t-5qUbW3r6","executionInfo":{"status":"ok","timestamp":1639576250399,"user_tz":-540,"elapsed":221,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"4e79724c-35bb-42eb-c3fe-5f25aae08cb1"},"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([ 0.        ,  0.0931455 ,  0.        , -0.        , -0.18441377,\n","         0.22091997,  0.        , -0.        , -0.00688338,  0.        ,\n","         0.06137183,  0.03564248,  0.        , -0.        , -0.        ,\n","         0.        , -0.00207498,  0.        ,  0.        ,  0.        ,\n","         0.        , -0.        ,  0.        ,  0.        , -0.        ,\n","         0.        ]), 11.09557738166954)"]},"metadata":{},"execution_count":130}]},{"cell_type":"markdown","source":["Ridge"],"metadata":{"id":"1kStyt7NJON6"}},{"cell_type":"code","source":["dfdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"4A7B3v1vDDuH","executionInfo":{"status":"ok","timestamp":1639571118743,"user_tz":-540,"elapsed":7,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"44da3398-4ebc-4fb1-d74f-5db3ac3389a1"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>No</th>\n","      <th>SF_oil</th>\n","      <th>SF_slickwater</th>\n","      <th>Y_first6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.226824</td>\n","      <td>-0.858988</td>\n","      <td>-1.961185</td>\n","      <td>-1.522041</td>\n","      <td>-1.299002</td>\n","      <td>-1.281383</td>\n","      <td>0.244388</td>\n","      <td>-1.141268</td>\n","      <td>-1.393265</td>\n","      <td>2.901430</td>\n","      <td>354</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99580.58333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.490518</td>\n","      <td>-0.628932</td>\n","      <td>-0.273031</td>\n","      <td>-0.287012</td>\n","      <td>-1.082439</td>\n","      <td>-0.110788</td>\n","      <td>0.415743</td>\n","      <td>-1.026866</td>\n","      <td>0.587010</td>\n","      <td>2.152315</td>\n","      <td>372</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82942.66667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.224418</td>\n","      <td>-0.443670</td>\n","      <td>0.241628</td>\n","      <td>-0.824768</td>\n","      <td>0.598911</td>\n","      <td>1.059806</td>\n","      <td>-1.097524</td>\n","      <td>1.182662</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>383</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55833.66667</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.558884</td>\n","      <td>-0.265648</td>\n","      <td>-0.927258</td>\n","      <td>-1.928906</td>\n","      <td>-0.062859</td>\n","      <td>1.515038</td>\n","      <td>-1.090512</td>\n","      <td>0.356052</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>395</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>95592.08333</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.635883</td>\n","      <td>-0.256663</td>\n","      <td>0.377477</td>\n","      <td>-0.714917</td>\n","      <td>0.501373</td>\n","      <td>1.059806</td>\n","      <td>-1.105412</td>\n","      <td>0.991992</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>397</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>104730.33330</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>275</th>\n","      <td>0.276364</td>\n","      <td>1.106074</td>\n","      <td>0.845244</td>\n","      <td>0.745442</td>\n","      <td>1.002558</td>\n","      <td>0.084311</td>\n","      <td>-0.031707</td>\n","      <td>0.470454</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>708</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>43417.00000</td>\n","    </tr>\n","    <tr>\n","      <th>276</th>\n","      <td>-0.481598</td>\n","      <td>1.365615</td>\n","      <td>0.057408</td>\n","      <td>0.766727</td>\n","      <td>-1.052605</td>\n","      <td>-0.500987</td>\n","      <td>1.678332</td>\n","      <td>-1.125566</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>716</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46754.00000</td>\n","    </tr>\n","    <tr>\n","      <th>277</th>\n","      <td>-0.298725</td>\n","      <td>1.125113</td>\n","      <td>-0.170568</td>\n","      <td>-0.162726</td>\n","      <td>-0.736141</td>\n","      <td>-0.110788</td>\n","      <td>0.609886</td>\n","      <td>-0.849655</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>718</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20921.00000</td>\n","    </tr>\n","    <tr>\n","      <th>278</th>\n","      <td>-0.043664</td>\n","      <td>1.141927</td>\n","      <td>-0.155112</td>\n","      <td>-0.058013</td>\n","      <td>-1.075134</td>\n","      <td>-0.175822</td>\n","      <td>0.612516</td>\n","      <td>-1.060513</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>720</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>56508.16667</td>\n","    </tr>\n","    <tr>\n","      <th>279</th>\n","      <td>-0.255413</td>\n","      <td>1.116825</td>\n","      <td>-0.123586</td>\n","      <td>0.764036</td>\n","      <td>-0.862377</td>\n","      <td>-0.631053</td>\n","      <td>1.670882</td>\n","      <td>-1.035838</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>722</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>36691.33333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>280 rows × 14 columns</p>\n","</div>"],"text/plain":["     TVD (ft)  Bot-Hole Northing (NAD83)  ...  SF_slickwater      Y_first6\n","0    1.226824                  -0.858988  ...              0   99580.58333\n","1    0.490518                  -0.628932  ...              0   82942.66667\n","2    1.224418                  -0.443670  ...              0   55833.66667\n","3    1.558884                  -0.265648  ...              0   95592.08333\n","4    1.635883                  -0.256663  ...              0  104730.33330\n","..        ...                        ...  ...            ...           ...\n","275  0.276364                   1.106074  ...              0   43417.00000\n","276 -0.481598                   1.365615  ...              0   46754.00000\n","277 -0.298725                   1.125113  ...              0   20921.00000\n","278 -0.043664                   1.141927  ...              0   56508.16667\n","279 -0.255413                   1.116825  ...              0   36691.33333\n","\n","[280 rows x 14 columns]"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["dfdf = pd.read_csv('/gdrive/My Drive/DS_contest/Finaldata1.csv')\n","dfdf = dfdf.drop('Unnamed: 0',axis=1)"],"metadata":{"id":"9DUJRuapCnio","executionInfo":{"status":"ok","timestamp":1639571116367,"user_tz":-540,"elapsed":242,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","x_std = dfdf.drop(['No','Y_first6'],axis=1)\n","y = dfdf['Y_first6']"],"metadata":{"id":"E_uOWayAJRTo","executionInfo":{"status":"ok","timestamp":1639571120856,"user_tz":-540,"elapsed":1,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["alpha_list = {'alpha' : np.arange(100,105,0.1)}\n","reg_sMAPE = GridSearchCV(Ridge(), param_grid = alpha_list, scoring=make_scorer(sMAPE, greater_is_better=False),cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzT1veud2z4o","executionInfo":{"status":"ok","timestamp":1639571179088,"user_tz":-540,"elapsed":3131,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"0c066184-daf8-4200-89b0-7cb49277d362"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 102.29999999999987}\n"]}]},{"cell_type":"code","source":["ridge_opt = Ridge(alpha=102.3).fit(x_std,y)\n","y_pred = ridge_opt.predict(x_std)\n","print(sMAPE(y, y_pred, False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhKsqiffJRE8","executionInfo":{"status":"ok","timestamp":1639571182952,"user_tz":-540,"elapsed":257,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"1e9f1b03-7f76-4137-ac31-45d75c2dee05"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["38.60243721018413\n"]}]},{"cell_type":"markdown","source":["Log Ridge"],"metadata":{"id":"FlZvvCy3KsL5"}},{"cell_type":"code","source":["def expsMAPE(actual_values, predicted_values, expsMAPE = True):\n","  predicted_values = np.exp(predicted_values)\n","  actual_values = np.exp(actual_values)\n","  return 1/len(actual_values) * np.sum(2*np.abs(actual_values - predicted_values) / (np.abs(actual_values) + np.abs(predicted_values)) * 100)"],"metadata":{"id":"0Euri5zIEwk3","executionInfo":{"status":"ok","timestamp":1639571460539,"user_tz":-540,"elapsed":239,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["log_list = []\n","for i in dfdf['Y_first6']:\n","  log_list.append(math.log(i))\n","\n","x_std = dfdf.drop(['No','Y_first6'],axis=1)\n","y = log_list"],"metadata":{"id":"wgAKGhnrKrqw","executionInfo":{"status":"ok","timestamp":1639571204875,"user_tz":-540,"elapsed":241,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["alpha_list = {'alpha' : np.arange(0.05,0.5,0.01)}\n","reg_sMAPE = GridSearchCV(Ridge(), param_grid = alpha_list, scoring=make_scorer(expsMAPE, greater_is_better=False), cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Hcnu8m8-vKF","executionInfo":{"status":"ok","timestamp":1639571604718,"user_tz":-540,"elapsed":2427,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"9f86ae46-e6f4-4c8a-bbc1-19a9e90eff75"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 0.2}\n"]}]},{"cell_type":"code","source":["logridge_opt = Ridge(alpha=0.2).fit(x_std,y)\n","y_pred = logridge_opt.predict(x_std)\n","print(sMAPE(y, y_pred, True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d24GZw1aKyy3","executionInfo":{"status":"ok","timestamp":1639571629774,"user_tz":-540,"elapsed":2,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"1ab91f8d-8261-486c-d177-112f65e03825"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["35.83408269845744\n"]}]},{"cell_type":"markdown","source":["Robust Regression (안함)"],"metadata":{"id":"lUMW2k6ILsZh"}},{"cell_type":"code","source":["from sklearn.linear_model import RANSACRegressor\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = df['Y_first6']"],"metadata":{"id":"bF4alxnmLgNq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_sMAPE = GridSearchCV(RANSACRegressor(), {}, scoring=make_scorer(sMAPE, greater_is_better=False))\n","reg_sMAPE.fit(x_std,y)\n","y_pred = reg_sMAPE.predict(x_std)\n","print(sMAPE(y, y_pred, False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nw0ZAYfmLveP","executionInfo":{"status":"ok","timestamp":1639321713641,"user_tz":-540,"elapsed":742,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"e53e4bfd-2c0f-40f1-8ba0-fe5d2e86d9c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["55.416019269604334\n"]}]},{"cell_type":"markdown","source":["Log Robust Regression (안함)"],"metadata":{"id":"BfJRnMQaMFtP"}},{"cell_type":"code","source":["log_list = []\n","for i in df_std['Y_first6']:\n","  log_list.append(math.log(i))\n","\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = log_list"],"metadata":{"id":"DmWwrbz9MEy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_sMAPE = GridSearchCV(RANSACRegressor(), {}, scoring=make_scorer(sMAPE, greater_is_better=False))\n","reg_sMAPE.fit(x_std,y)\n","y_pred = reg_sMAPE.predict(x_std)\n","print(sMAPE(y, y_pred, True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmfwT9l2MJlV","executionInfo":{"status":"ok","timestamp":1639321758486,"user_tz":-540,"elapsed":723,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"0972e229-4cce-4685-acc8-30be05f8a375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["58.60719943646769\n"]}]},{"cell_type":"markdown","source":["Elastic Net"],"metadata":{"id":"uILbxIroJQEE"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = df['Y_first6']"],"metadata":{"id":"KZZ-mSfUH1_k","executionInfo":{"status":"ok","timestamp":1639572846210,"user_tz":-540,"elapsed":226,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["param_list = {'alpha' : np.arange(4,8,0.1), 'l1_ratio' : np.arange(0, 1.1, 0.1)}\n","\n","reg_sMAPE = GridSearchCV(ElasticNet(), param_grid = param_list, scoring=make_scorer(sMAPE, greater_is_better=False), cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3lNOMBEKDor","executionInfo":{"status":"ok","timestamp":1639573887501,"user_tz":-540,"elapsed":19822,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"ffd133d4-a299-4af1-f988-aa49e6d361d3"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.422e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.526e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.525e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.047e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.363e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.474e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.535e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.440e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.541e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.541e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.684e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.707e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+10, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.618e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.942e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.579e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.367e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.911e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.583e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.733e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+09, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.919e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.489e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.534e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.743e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.352e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.606e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.613e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.749e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.497e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.616e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.038e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.499e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.879e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.387e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.755e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.740e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.477e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.236e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.770e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.128e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.641e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.517e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.637e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.782e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.526e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.658e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.241e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+10, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.883e+09, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+11, tolerance: 6.139e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e+11, tolerance: 5.407e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+11, tolerance: 3.755e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+11, tolerance: 5.856e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+11, tolerance: 5.947e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 6.79999999999999, 'l1_ratio': 0.9}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+11, tolerance: 6.139e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+08, tolerance: 5.407e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.682e+09, tolerance: 3.755e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+11, tolerance: 5.856e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+11, tolerance: 5.947e+07\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]}]},{"cell_type":"code","source":["elastic_opt = ElasticNet(alpha=6.8, l1_ratio = 0.9).fit(x_std,y)\n","y_pred = elastic_opt.predict(x_std)\n","print(sMAPE(y, y_pred, False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vEmhE2IOJ7D","executionInfo":{"status":"ok","timestamp":1639573995283,"user_tz":-540,"elapsed":241,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"f04a697e-7cd2-474b-b951-6777ebd9c119"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["38.92396130449107\n"]}]},{"cell_type":"markdown","source":["Log ElasticNet"],"metadata":{"id":"UMQVrVHdOtGn"}},{"cell_type":"code","source":["log_list = []\n","for i in df_std['Y_first6']:\n","  log_list.append(math.log(i))\n","\n","x_std = df_std.drop(['No','Y_first6'],axis=1)\n","y = log_list"],"metadata":{"id":"iQeLj5vrOeYM","executionInfo":{"status":"ok","timestamp":1639574221005,"user_tz":-540,"elapsed":253,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["alpha_list = {'alpha' : np.arange(0.02,0.04,0.001), 'l1_ratio' : np.arange(0, 1.1, 0.1) }\n","reg_sMAPE = GridSearchCV(ElasticNet(), param_grid = alpha_list, scoring=make_scorer(expsMAPE, greater_is_better=False), cv=5)\n","reg_sMAPE.fit(x_std,y)\n","print('최적의 parameter: ', reg_sMAPE.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzCE9ITFPTYk","executionInfo":{"status":"ok","timestamp":1639574372102,"user_tz":-540,"elapsed":7675,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"87104b3d-a51c-4f89-9d46-b2cb28d3ed1c"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.358e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.499e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.631e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.491e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.637e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.380e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.525e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.537e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.505e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.514e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.491e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.526e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.683e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.416e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.568e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.420e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.537e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.697e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.541e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e+01, tolerance: 1.001e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e+01, tolerance: 8.321e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+01, tolerance: 7.559e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+01, tolerance: 9.500e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+01, tolerance: 9.045e-03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n","  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"]},{"output_type":"stream","name":"stdout","text":["최적의 parameter:  {'alpha': 0.03100000000000001, 'l1_ratio': 1.0}\n"]}]},{"cell_type":"code","source":["logelastic_opt = ElasticNet(alpha=0.031, l1_ratio = 1).fit(x_std,y)\n","y_pred = logelastic_opt.predict(x_std)\n","print(sMAPE(y, y_pred, True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"siYGXU1CP_ph","executionInfo":{"status":"ok","timestamp":1639574441064,"user_tz":-540,"elapsed":235,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"303a6382-89b2-4104-a164-0273fec896d9"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["36.86207494742843\n"]}]},{"cell_type":"markdown","source":["Finaldata1.csv 생성"],"metadata":{"id":"sDCvl_Iic9RO"}},{"cell_type":"code","source":["df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"0l5ahyR-dSZO","executionInfo":{"status":"ok","timestamp":1639233673685,"user_tz":-540,"elapsed":12,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"dc90b6cf-4fe0-4ee2-e262-a6a801eb493c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No</th>\n","      <th>MD (All Wells) (ft)</th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole direction (N/S)/(E/W)</th>\n","      <th>Bot-Hole Easting (NAD83)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Total Fluid Pumped (m3)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Completed Length (m)</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Load Fluid Rec (m3)</th>\n","      <th>Load Fluid (m3)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Avg Proppant Placed / Meter (tonne)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Avg Proppant 1 Placed (tonne)</th>\n","      <th>Total Proppant 1 Placed (tonne)</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>Total Sand Proppant Placed (tonne)</th>\n","      <th>Y_first6</th>\n","      <th>SF_oil</th>\n","      <th>SF_water</th>\n","      <th>SF_slickwater</th>\n","      <th>PC_ceramic</th>\n","      <th>PC_sand</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>354</td>\n","      <td>15384</td>\n","      <td>10746</td>\n","      <td>0.583087</td>\n","      <td>0.520701</td>\n","      <td>0.202393</td>\n","      <td>1197.61</td>\n","      <td>66.53</td>\n","      <td>3214.7</td>\n","      <td>178.59</td>\n","      <td>18</td>\n","      <td>1249.60</td>\n","      <td>73.50</td>\n","      <td>1148.37</td>\n","      <td>3248.30</td>\n","      <td>2.57</td>\n","      <td>0.96</td>\n","      <td>40.0</td>\n","      <td>35.48</td>\n","      <td>638.70</td>\n","      <td>638.70</td>\n","      <td>558.91</td>\n","      <td>99580.58333</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>372</td>\n","      <td>20167</td>\n","      <td>10440</td>\n","      <td>1.059932</td>\n","      <td>0.402927</td>\n","      <td>0.242269</td>\n","      <td>4212.32</td>\n","      <td>117.01</td>\n","      <td>9727.2</td>\n","      <td>270.20</td>\n","      <td>36</td>\n","      <td>2711.90</td>\n","      <td>77.41</td>\n","      <td>1604.27</td>\n","      <td>11438.43</td>\n","      <td>3.59</td>\n","      <td>1.55</td>\n","      <td>60.0</td>\n","      <td>13.80</td>\n","      <td>496.97</td>\n","      <td>496.97</td>\n","      <td>3715.35</td>\n","      <td>82942.66667</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>383</td>\n","      <td>18832</td>\n","      <td>10745</td>\n","      <td>1.913723</td>\n","      <td>0.351151</td>\n","      <td>0.274381</td>\n","      <td>5131.40</td>\n","      <td>95.03</td>\n","      <td>52997.8</td>\n","      <td>981.44</td>\n","      <td>54</td>\n","      <td>2275.37</td>\n","      <td>42.88</td>\n","      <td>914.98</td>\n","      <td>52997.80</td>\n","      <td>23.29</td>\n","      <td>2.26</td>\n","      <td>55.0</td>\n","      <td>95.03</td>\n","      <td>5131.40</td>\n","      <td>0.00</td>\n","      <td>5131.40</td>\n","      <td>55833.66667</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No  MD (All Wells) (ft)  TVD (ft)  ...  SF_slickwater  PC_ceramic  PC_sand\n","0  354                15384     10746  ...              0           1        0\n","1  372                20167     10440  ...              0           1        0\n","2  383                18832     10745  ...              0           0        1\n","\n","[3 rows x 28 columns]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["dataframe = df_std.drop(['MD (All Wells) (ft)', 'Bot-Hole direction (N/S)/(E/W)', 'Bot-Hole Easting (NAD83)', \n","         'Total Fluid Pumped (m3)', 'Completed Length (m)', 'Load Fluid Rec (m3)', 'Load Fluid (m3)',\n","         'Avg Proppant Placed / Meter (tonne)', 'Avg Proppant 1 Placed (tonne)', 'Total Proppant 1 Placed (tonne)', \n","         'Total Sand Proppant Placed (tonne)', 'SF_water', 'PC_ceramic', 'PC_sand'], axis=1)"],"metadata":{"id":"dit30FPhdYA2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe.to_csv('/gdrive/My Drive/DS_contest/Finaldata1.csv')"],"metadata":{"id":"8G7KUg7eeGPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe['new'] = dataframe['Y_first6']\n","dataframe = dataframe.drop('Y_first6',axis=1)\n","dataframe.rename(columns={'new':'Y_first6'},inplace=True)\n","dataframe.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"aMB2ePRhfDqS","executionInfo":{"status":"ok","timestamp":1639233674612,"user_tz":-540,"elapsed":5,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"76d3a761-651a-42da-a0ff-fa9f5541046c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>No</th>\n","      <th>SF_oil</th>\n","      <th>SF_slickwater</th>\n","      <th>Y_first6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.226824</td>\n","      <td>-0.858988</td>\n","      <td>-1.961185</td>\n","      <td>-1.522041</td>\n","      <td>-1.299002</td>\n","      <td>-1.281383</td>\n","      <td>0.244388</td>\n","      <td>-1.141268</td>\n","      <td>-1.393265</td>\n","      <td>2.901430</td>\n","      <td>354</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99580.58333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.490518</td>\n","      <td>-0.628932</td>\n","      <td>-0.273031</td>\n","      <td>-0.287012</td>\n","      <td>-1.082439</td>\n","      <td>-0.110788</td>\n","      <td>0.415743</td>\n","      <td>-1.026866</td>\n","      <td>0.587010</td>\n","      <td>2.152315</td>\n","      <td>372</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82942.66667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.224418</td>\n","      <td>-0.443670</td>\n","      <td>0.241628</td>\n","      <td>-0.824768</td>\n","      <td>0.598911</td>\n","      <td>1.059806</td>\n","      <td>-1.097524</td>\n","      <td>1.182662</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>383</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55833.66667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   TVD (ft)  Bot-Hole Northing (NAD83)  ...  SF_slickwater     Y_first6\n","0  1.226824                  -0.858988  ...              0  99580.58333\n","1  0.490518                  -0.628932  ...              0  82942.66667\n","2  1.224418                  -0.443670  ...              0  55833.66667\n","\n","[3 rows x 14 columns]"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["다시"],"metadata":{"id":"thCMNLYgSyoV"}},{"cell_type":"code","source":["dataframe = pd.read_csv('/gdrive/My Drive/DS_contest/Finaldata1.csv')"],"metadata":{"id":"YgQMx-erffqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"38HdP4ko9ls_","executionInfo":{"status":"ok","timestamp":1639234038650,"user_tz":-540,"elapsed":282,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"3aa89fc7-1276-46c5-f63e-14be6ef6bf2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>No</th>\n","      <th>SF_oil</th>\n","      <th>SF_slickwater</th>\n","      <th>Y_first6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.226824</td>\n","      <td>-0.858988</td>\n","      <td>-1.961185</td>\n","      <td>-1.522041</td>\n","      <td>-1.299002</td>\n","      <td>-1.281383</td>\n","      <td>0.244388</td>\n","      <td>-1.141268</td>\n","      <td>-1.393265</td>\n","      <td>2.901430</td>\n","      <td>354</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99580.58333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.490518</td>\n","      <td>-0.628932</td>\n","      <td>-0.273031</td>\n","      <td>-0.287012</td>\n","      <td>-1.082439</td>\n","      <td>-0.110788</td>\n","      <td>0.415743</td>\n","      <td>-1.026866</td>\n","      <td>0.587010</td>\n","      <td>2.152315</td>\n","      <td>372</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82942.66667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.224418</td>\n","      <td>-0.443670</td>\n","      <td>0.241628</td>\n","      <td>-0.824768</td>\n","      <td>0.598911</td>\n","      <td>1.059806</td>\n","      <td>-1.097524</td>\n","      <td>1.182662</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>383</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55833.66667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   TVD (ft)  Bot-Hole Northing (NAD83)  ...  SF_slickwater     Y_first6\n","0  1.226824                  -0.858988  ...              0  99580.58333\n","1  0.490518                  -0.628932  ...              0  82942.66667\n","2  1.224418                  -0.443670  ...              0  55833.66667\n","\n","[3 rows x 14 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["df_std.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"BltGoHOL9hvL","executionInfo":{"status":"ok","timestamp":1639234024574,"user_tz":-540,"elapsed":284,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"7756b88c-556b-4e62-e438-ac5f670dad2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MD (All Wells) (ft)</th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole direction (N/S)/(E/W)</th>\n","      <th>Bot-Hole Easting (NAD83)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Total Fluid Pumped (m3)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Stages Actual</th>\n","      <th>Completed Length (m)</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Load Fluid Rec (m3)</th>\n","      <th>Load Fluid (m3)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Avg Proppant Placed / Meter (tonne)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Avg Proppant 1 Placed (tonne)</th>\n","      <th>Total Proppant 1 Placed (tonne)</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>Total Sand Proppant Placed (tonne)</th>\n","      <th>No</th>\n","      <th>SF_oil</th>\n","      <th>SF_water</th>\n","      <th>SF_slickwater</th>\n","      <th>PC_ceramic</th>\n","      <th>PC_sand</th>\n","      <th>Y_first6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.562520</td>\n","      <td>1.226824</td>\n","      <td>-0.247911</td>\n","      <td>-0.248694</td>\n","      <td>-0.858988</td>\n","      <td>-1.961185</td>\n","      <td>-1.522041</td>\n","      <td>-1.368958</td>\n","      <td>-1.299002</td>\n","      <td>-1.281383</td>\n","      <td>-1.848096</td>\n","      <td>0.244388</td>\n","      <td>-0.111781</td>\n","      <td>-1.357159</td>\n","      <td>-1.141268</td>\n","      <td>-1.344501</td>\n","      <td>-1.393265</td>\n","      <td>-1.194837</td>\n","      <td>-1.439424</td>\n","      <td>2.901430</td>\n","      <td>-2.107496</td>\n","      <td>354</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99580.58333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.933927</td>\n","      <td>0.490518</td>\n","      <td>-0.223838</td>\n","      <td>-0.782448</td>\n","      <td>-0.628932</td>\n","      <td>-0.273031</td>\n","      <td>-0.287012</td>\n","      <td>-1.027266</td>\n","      <td>-1.082439</td>\n","      <td>-0.110788</td>\n","      <td>0.709431</td>\n","      <td>0.415743</td>\n","      <td>0.221538</td>\n","      <td>-0.942101</td>\n","      <td>-1.026866</td>\n","      <td>-0.621411</td>\n","      <td>0.587010</td>\n","      <td>-1.545018</td>\n","      <td>-1.497726</td>\n","      <td>2.152315</td>\n","      <td>-0.464036</td>\n","      <td>372</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>82942.66667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.237135</td>\n","      <td>1.224418</td>\n","      <td>-0.180734</td>\n","      <td>-1.017098</td>\n","      <td>-0.443670</td>\n","      <td>0.241628</td>\n","      <td>-0.824768</td>\n","      <td>1.243021</td>\n","      <td>0.598911</td>\n","      <td>1.059806</td>\n","      <td>-0.054050</td>\n","      <td>-1.097524</td>\n","      <td>-0.282418</td>\n","      <td>1.164038</td>\n","      <td>1.182662</td>\n","      <td>0.248748</td>\n","      <td>0.091941</td>\n","      <td>-0.232970</td>\n","      <td>0.408689</td>\n","      <td>-0.474427</td>\n","      <td>0.273257</td>\n","      <td>383</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>55833.66667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   MD (All Wells) (ft)  TVD (ft)  ...  PC_sand     Y_first6\n","0            -1.562520  1.226824  ...        0  99580.58333\n","1             0.933927  0.490518  ...        0  82942.66667\n","2             0.237135  1.224418  ...        1  55833.66667\n","\n","[3 rows x 28 columns]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["dataframe = dataframe.drop('Y_first6',axis=1)"],"metadata":{"id":"cvorg8lwSyBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = dataframe.drop('Stages Actual',axis=1)\n","dataframe['Completed Length (m)'] = df_std['Completed Length (m)']\n","dataframe['Load Fluid (m3)'] = df_std['Load Fluid (m3)']\n","dataframe['Total Proppant 1 Placed (tonne)'] = df_std['Total Proppant 1 Placed (tonne)']\n","dataframe['PC_ceramic'] = df['PC_ceramic']\n","dataframe['PC_sand'] = df['PC_sand']\n","dataframe['Y_first6'] = df['Y_first6']\n","dataframe.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"UxhNoppMTcAr","executionInfo":{"status":"ok","timestamp":1639234076556,"user_tz":-540,"elapsed":291,"user":{"displayName":"Kwon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1jMyKXfXpJ85sE1IQDrRo3pA-rkHcHIhtXrIRkg=s64","userId":"05247163753736836748"}},"outputId":"46b99a92-a1ad-4c46-e462-682fbac81b18"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TVD (ft)</th>\n","      <th>Bot-Hole Northing (NAD83)</th>\n","      <th>Total Proppant Placed (tonne)</th>\n","      <th>Avg Proppant Placed per Stage (tonne)</th>\n","      <th>Avg Fluid Pumped per Stage (m3)</th>\n","      <th>Avg Frac Spacing (m)</th>\n","      <th>Avg Fluid Pumped / Meter (m3)</th>\n","      <th>Proppant Size 1</th>\n","      <th>Total Ceramic Proppant Placed (tonne)</th>\n","      <th>No</th>\n","      <th>SF_oil</th>\n","      <th>SF_slickwater</th>\n","      <th>Completed Length (m)</th>\n","      <th>Load Fluid (m3)</th>\n","      <th>Total Proppant 1 Placed (tonne)</th>\n","      <th>PC_ceramic</th>\n","      <th>PC_sand</th>\n","      <th>Y_first6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.226824</td>\n","      <td>-0.858988</td>\n","      <td>-1.961185</td>\n","      <td>-1.522041</td>\n","      <td>-1.299002</td>\n","      <td>0.244388</td>\n","      <td>-1.141268</td>\n","      <td>-1.393265</td>\n","      <td>2.901430</td>\n","      <td>354</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1.848096</td>\n","      <td>-1.357159</td>\n","      <td>-1.439424</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>99580.58333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.490518</td>\n","      <td>-0.628932</td>\n","      <td>-0.273031</td>\n","      <td>-0.287012</td>\n","      <td>-1.082439</td>\n","      <td>0.415743</td>\n","      <td>-1.026866</td>\n","      <td>0.587010</td>\n","      <td>2.152315</td>\n","      <td>372</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.709431</td>\n","      <td>-0.942101</td>\n","      <td>-1.497726</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>82942.66667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.224418</td>\n","      <td>-0.443670</td>\n","      <td>0.241628</td>\n","      <td>-0.824768</td>\n","      <td>0.598911</td>\n","      <td>-1.097524</td>\n","      <td>1.182662</td>\n","      <td>0.091941</td>\n","      <td>-0.474427</td>\n","      <td>383</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.054050</td>\n","      <td>1.164038</td>\n","      <td>0.408689</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>55833.66667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   TVD (ft)  Bot-Hole Northing (NAD83)  ...  PC_sand     Y_first6\n","0  1.226824                  -0.858988  ...        0  99580.58333\n","1  0.490518                  -0.628932  ...        0  82942.66667\n","2  1.224418                  -0.443670  ...        1  55833.66667\n","\n","[3 rows x 18 columns]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[""],"metadata":{"id":"nGu5YS8r-TlZ"},"execution_count":null,"outputs":[]}]}